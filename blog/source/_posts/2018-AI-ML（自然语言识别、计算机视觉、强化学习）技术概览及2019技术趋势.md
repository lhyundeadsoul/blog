---
title: 2018 AI&ML（自然语言识别、计算机视觉、强化学习）技术概览及2019技术趋势
date: 2019-04-02 01:00:51
tags: 
- AI
categories: 
- 技术趋势
comments: true
---

>一篇国外AI&ML领域大咖的总结文章，翻译的时候我是奔着“信达雅”去的，结果脸着地还没接住，翻译的水平有限，有兴趣的也可以看[原文](https://www.analyticsvidhya.com/blog/2018/12/key-breakthroughs-ai-ml-2018-trends-2019/)
## 前言

最近几年，人工智能的热度和机器学习技术的成熟度有了一个梦幻般的增长。这些技术已经从边缘领域发展成为了技术主流，并且已经现如今已经影响了数以百万计的人。各个国家也增加了在AI领域的投入以使自己保持竞争优势。

对于数据科学专家来说情况也是一样的， 在过去几年，即使只懂一点相关工具和技术你就可以高枕无忧了。但是现在已经完全不行了。在这个领域发生了太多事情，且有太多东西需要学习以保持和业界同步，这有时令人难以置信。

这就是我为什么想以一个数据科学从业者的视角，回顾一下在几个关键领域里人工智能领域里都取得了哪些发展？哪些突破？2018发生了些什么？2019又有哪些期待？

## 我们将会在文中提到的领域

* 自然语言处理
* 计算机视觉
* 工具和库
* 强化学习
* AI伦理

<!--more-->

## 自然语言处理NLP


![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/11/asset-v1AnalyticsVidhyaNLP1012018_T1type%40assetblock%40nlp2.jpg)

让机器理解单词和句子在之前一直是一个梦，即使是人类自己在面对语言巨量的细节时，有时也会显得手足无措。但是2018年绝对是NLP的转折年。

我们已经看到一个接一个的技术突破—— ULMFiT, ELMO, OpenAI的 Transformer 以及 Google的BERT 等等。迁移学习在NLP任务上的成功应用打开了一扇通往无限可能的大门。Sebastian Ruder 的播客让我们相信在他的这个领域里有了多么长足的发展。

现在我们来更细致地看一下这些关键的进展吧。如果你希望在NLP领域里找学习的切入点，或者正在找相关的库，请先确保你已经学习过[NLP using Python](https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+NLP101+2018_T1/about)的课程了。这是一个开始NLP学习的好地方。

### ULMFiT

由Sebastian Ruder 和 fast.ai的 Jeremy Howard共同设计的ULMFiT是让迁移学习成为热点的首个框架。对于没有多少经验的人来说，它代表了“通用语言模型”，Jeremy和Sebastian在这个框架中真正实现了通用二字的含义，它几乎可以应用于所有NLP任务。

不需要更多的ULMFiT或其它的框架介绍了，因为你根本不需要从头开始训练模型！这些研究人员已经做好了最困难的部分。你只需要在你的项目中，学会并应用他们的研究成果即可。ULMFiT在六个文本分类任务里表现优于其他最先进的方法。

关于如何使用此框架解决文本分类问题，你可以阅读由Prateek写的这个很棒的[教程](https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/)。


### ELMo

ELMo是Embeddings from Language Models的简写，即使不提它奇怪的名字，ELMo在发布后依然能迅速获得机器学习社区的关注。

ELMo在考虑了单词在句子和段落中的上下文之后，使用了各种模型去获知单词的内在含义(embeddings)。语境是一个很重要，同时又大部分人都没有掌握的NLP的组成部分。ELMo使用了双向的LSTMs去理解单词内含(embeddings)。你可以阅读[这篇文章](https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/)去快速了解LSTMs的工作原理。

就像ULMFiT一样，ELMo显著地提高了各种类型NLP任务的计算性能，比如情绪分析和问答分析。可以阅读[这篇文章](https://allennlp.org/elmo)了解更多。

### BERT

不少专家认为BERT的发布开启了NLP的新纪元。继ULMFiT 和 ELMo之后，BERT在性能表现上碾压了对手。正如[原始论文](https://arxiv.org/abs/1810.04805)里说的“BERT是概念极简且经验强大的(BERT is conceptually simple and empirically powerful)”。

BERT在11项NLP任务中获得了最优的结果，可以看一下他们在SQuAD基准测试中的表现：

|SQuAD v1.1 Leaderboard (Oct 8th 2018)	|Test EM|	Test F1|
|----|----|----|
|1st Place Ensemble – BERT|	87.4|	93.2|
|2nd Place Ensemble – nlnet|	86.0|	91.7|
|1st Place Single Model – BERT|	85.1|	91.8|
|2nd Place Single Model – nlnet|	83.5|	90.1|

你可以在自己的机器上使用[PyTorch的实现](https://github.com/huggingface/pytorch-pretrained-BERT)或者Google的[Tensorflow实现](https://github.com/google-research/bert)去验证这个结果。

我非常肯定你会好奇BERT在这一点上代表了什么。它是翻译机的双向编码表示(Bidirectional Encoder Representations from Transformers)。如果第一次能做对，就会是满分。


### Facebook PyText

Facebook怎么会离开赛道呢？他们已经开源了自己的深度学习NLP框架，叫PyText。它在本周初早些时候刚刚发布，所以我还在实验当中，但是从早期的评论来看，是非常有潜力的。根据Facebook发表的研究，PyText使对话模型的准确率提升了10%的同时降低了训练时间。

PyText实际上还是弱于Facebook其它产品的，比如FB Messenger。因此，使用这个框架可以为你的工作(your own portfolio)添加现实世界的价值(除了您将获得的宝贵知识以外)。

你可以在他们的[GitHub repo](https://github.com/facebookresearch/pytext)里下载源码。

### Google Duplex

如果你还没有听说过Google Duplex，那你可能out了。Sundar Pichai 用这个demo震撼了当时在场的观众，并且从那以为它就一直是新闻的头条了。

<iframe width="420" height="315" src="https://www.youtube.com/embed/NO0-5MuJvew" frameborder="0" allowfullscreen></iframe>


因为这是一个Google的产品，所以他们很可能会在未来将其开源。这的确是一个非常棒的音频处理应用。当然它也带来了道德和隐私问题，但那是本文后面才要说的了。现在，还是让我们感慨一下这些年我们已经和机器学习走了多远吧。

### 2019年NLP值得期待的事

还有谁比 Sebastian Ruder 他自己更能预测NLP在2019年的发展呢，他的想法如下：
>预训练语言模型内含(embeddings)将会变得普遍。不使用此类方法，将很难得到最优的模型。
我们将看到预训练的表示( pretrained representations)可以给语言模型内含提供补充的专业信息。我们将可以根据任务的需求组合不同类型的预训练的表示.
我们将可以看到会在多语言应用和跨语言模型上会有更多的进展。尤其在跨语言单词内含的基础上，我们将会看到深入的预训练跨语言表示。

## 计算机视觉
![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/12/CV.jpg)

这是现在深度学习领域中最受欢迎的领域了。我认为现在已经渡过了计算机视觉的初期，进入了精炼化的阶段。无论是图像还是视频，我们都已经看到了太多可以轻而易举完成计算机视觉任务的框架。

在 Analytics Vidhya，我们已经用了很多时间去普及这些概念。你可以从[这里](https://www.analyticsvidhya.com/blog/category/deep-learning/)看到我们关于计算机视觉的文章，主题涵盖了从“在图像和视频中完成物体识别”到“预训练模型列表”，这些资料可以帮助你开始你的深度学习旅程。

以下是我精心挑选的计算机视觉的优秀项目。

如果你对这个领域很好奇（实际上这可能是未来工业界最火的工作之一），那么可以通过学习我们的[深度学习和计算机视觉](https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+CVDL101+CVDL101_T1/about)课程。

### BigGANs

Ian Goodfellow在2014年设计了GANs（生成对抗网络）概念，并在随后的时间里这一概念衍生出了很多多样化的应用。每年我们都可以看到这个原始的概念通过调整适应了很多实际的案例。但是有一件事从今年开始发生——机器生成的图像非常好辨认出来。框架里总是会有一些不一致性会导致区别非常明显。

但是最近几个月，这一边界已经开始变得模糊。随着[BigGANs](https://arxiv.org/pdf/1809.11096.pdf)的建立，这一边界有可能被彻底消除。看看下面机器生成的图片，你几乎无法看出这些图片有什么问题。
![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/12/Screenshot-from-2018-12-18-18-06-19.png)
无论是忧虑还是兴奋，我们不得不承认GANs正在重塑我们对数字图像（视频）的认知。

对于一些数据科学家来说，这些模型首先在ImageNet上训练，然后是JFT-300M，以展示它们可以很好的从一个数据集迁移到另一个数据集。我同样会引导你到一个可视化理解的GAN的[学习页](https://gandissect.csail.mit.edu/)。

### Fast.ai可以在18分钟内完成在 ImageNet上的训练

这是一个非常大的进展。 我们通常认为要想获得一个合适的深度学习任务，往往需要大量的数据以及繁重的计算任务。这里包括了在ImageNet上从头开始的训练。我可以肯定我们所有人都是这么认为的，而Fast.ai的人找到了这么快的办法证明我们其实想错了。

他们用18分钟训练出的模型可以达到93%的准确率。而他们在[blog](http://www.fast.ai/2018/08/10/fastai-diu-imagenet/)中提到他们用的硬件，仅是16台包涵了8个 NVIDIA V100 GPU的AWS公开实例。他们是使用Fastai和PyTorch库构建的此算法。

![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/08/v2-718f95df083b2d715ee29b018d9eb5c2_r.jpg)


所有这些加在一起的成本仅有40美元！[这里](http://www.fast.ai/2018/08/10/fastai-diu-imagenet/)有Jeremy关于这项技术更详细的说明。这是所有人的胜利！

### NVIDIA的 vid2vid 技术

图像处理在最近4、5年有了巨大的飞跃，但是视频呢？事实证明，从单帧到多帧的方法迁移比大多数人想像的还要难一些。你能拿着一个视频的时间序列数据去预测下一帧是什么内容吗？之前有过一些探索，但是最好的结论也都并不明确。

NVIDIA在今年早些时候开源了他们的方案，并获得了广泛的赞誉。他们的vid2vid技术的目标是学习一个从输入视频到输出视频的映射函数，而输出视频可以以令人难以置信的准确度延续了输入视频的内容。

![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/08/v2V1.png)


你可以从[他们的Github](https://github.com/NVIDIA/vid2vid)上看到他们的PyTorch的实现。

### 2019年计算机视觉领域展望

正如我之前提到的，我们在2019年应该只会看到一些改进，但不会是大的发明。自动驾驶、人脸识别和虚拟现实貌似都没有什么太多的变化。你可以随便质疑我此处的观点，并加上你的观点，我非常想知道还有什么是我们现在还没看到，但是还值得期待的。

即使有政治因素的干预和政府的许可限制，无人机最终会在美国获得批准（印度还远远不能）。个人角度上说，我希望有更多的研究成果可以在真实场景里实施出来。像CVPR和ICML这些会议已经代表了最新进展，但是他们的成果离现实应用又有多远的距离啊？

视觉问题解答和视觉对话系统最终可能很快完成他们让人期待以久的首次亮相。这些系统缺少泛化能力，但是值得期待的是，我们将会很快看到一些多模型整合的方案。

有监督学习是今年的主角。我可以打赌在明年它将被用在更多的研究之中。有一个非常棒的学习思路——让我们的输入数据直接决定标签，而不是浪费很多时间手工标注。让我们祈祷吧。

## 工具和类库

本节将会吸引很多数据科学家的注意，因为工具和类库是数据科学家的工作基础。我参与了大量关于哪个工具最好，哪个框架取代了哪个框架，哪个类库是金融计算的代表之类的争论。我相信这些问题有很多也与你的工作相关。

但是有一点我们得承认：我们需要保持对这个领域里最新工具的跟进，否则就会埋下更多的风险。Python极速取代一切并成为行业领导者的故事就是一个充分的例子。虽然很多问题的答案可能是一些主观的选择（比如你们公司用什么工具，你们从现有框架迁移到新框架的可行性决策等），但是如果你现在还没有在考虑最优解决方案，我劝你现在就开始吧。

所以到底明年谁会是头条呢？让我们拭目以待吧。

### PyTorch 1.0

PyTorch炒作得太厉害了，我在本文已经提到了很多次，我会让我的同事 Faizan Shaikh去[介绍这个框架的细节](https://www.analyticsvidhya.com/blog/2018/02/pytorch-tutorial/)。

这是我非常欣赏的必读文章之一，因为有时候TensorFlow运行会很慢，所以给PyTorch了一个迅速抢占市场的机会，PyTorch流行起来的速度比TensorFlow快了一倍。我看到的大部分开源代码都是对PyTorch概念的实现。这绝非巧合，PyTorch非常灵活，并且它的最新版本已经大规模的增强了Facebook的产品和服务，其中包括每天60亿次的文本翻译工作。

PyTorch的2019年的采用率正在增长，所以对于任何人来说，现在就是上车的好时候。

### AutoML

自动化机器学习技术在过去几年中取得了很大的进展。一些像RapidMiner, KNIME, DataRobot and H2O.ai这样的公司，凭借着他们出色的产品展示了这项服务巨大的潜力。

你能想像只需要拖拽，而不需要编码就能完成机器学习和深度学习的任务吗？这个场景在未来已经不难实现了。除了这些公司的产品外，机器学习领域还有一个重大的产品发布——Auto Keras！

![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/08/auto-keras.png)


它是一个可以执行AutoML任务的开源库，这个项目的初衷是让不懂机器学习的领域专家们也可以使用深度学习技术。你可以在[这里](https://autokeras.com/)看到这个项目，未来几年它将蓄势待发。

### TensorFlow.js——浏览器里的深度学习

我们已经在IDE和Notebook里设计构建了很多机器学习的模型。为什么不向外走一步，去尝试一些新的技术呢？没错，我们可以在我们的浏览器里的去运行深度学习模型了！
![](https://js.tensorflow.org/images/TF_JS_lockup.png)

这要感谢[TensorFlow.js项目](https://js.tensorflow.org/)，它有一些demo，充分展示了这个想法有多酷。以下是TensorFlow.js的三个主要特点：

用JavaScript开发和部署机器学习模型
在浏览器里运行已经存在的TensorFlow模型
重训练已经存在的TensorFlow模型

### 2019年AutoML展望

我想在本章中只强调AutoML技术。因为我认为这项技术才是未来数据科学领域里的游戏规则改变者。不要只是听我说，让我们来看看H2O.ai的 [Marios Michailidis](https://soundcloud.com/datahack-radio/episode-3-marios-michailidis)和 Kaggle Grandmaste是怎么看待2019AutoML的：

>机器学习在成为未来重要趋势的道路上一路高歌猛进。这一扩展增加了对这一领域熟练应用的需求。鉴于它的成长，自动化是把数据科学资源最优化利用的关键。这一技术的应用范围无限宽广：信用，保险，欺诈，计算机视觉，声学，传感器，推荐器，预测，NLP，你来定义它。在这个领域里工作是一种荣幸。这个重要的趋势可以这么理解：
>
1. 为辅助描述和理解数据，提供智能化的可视化操作界面
2. 在给定的数据集上寻找、构建、抽象更好的特征
3. 快速建立强大的有预见能力的模型
4. 通过机器学习，给黑盒模型和生产模型提供可解释性
5. 促进这些模型的产生

## 强化学习
![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/11/RL.png)

如果让我选一个希望看到更多进展的领域，我想会是强化学习。除了偶尔能看到不定期的头条新闻之外，还没有发现有什么颠覆性的突破。社区里，大家普遍认为它太重数学，没有可以使用的真正可工业化的应用。

虽然这在某种程度上可能是正确的，但是我仍然希望在明年看到更多关于强化学习的使用案例。在我每个月发布的GitHub和Reddit系列里，我倾向于至少保留有一个git仓库或相关讨论。在所有研究方向里，这里可能会诞生下一个重大突破。

OpenAI已经发布了一个非常有用的工具包，可以帮助初学者了解这个领域，你也可以看看这篇[对初学者非常友好的文章](https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/)（对我真的非常有帮助）。

### OpenAI在深度强化学习的应用
![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/12/spinning-up-in-rl-768x461.png)


如果说强化学习的研究进展缓慢，那么相关的教育材料就可以说是非常少了。但是就像OpenAI说的那样，他们已经开源了关于这个主题的一些非常棒的材料。他们管这个项目叫“Spinning Up in Deep RL”，你可以从[这里](https://spinningup.openai.com/en/latest/)了解到它们。

它是一个非常全面的关于强化学习的资源列表，他们让代码和名词解释保持尽可能简单。它里面包含很多有用的材料，比如强化学习的术语，如何成长为强化学习研究员的建议，一个重要论文的列表，一个拥有非常好文档的代码仓库，甚至还有一些帮助你入门的练习。

不要再拖延，如果你计划入门强化学习，现在就开始吧。

### Google开源的Dopamine

为了加速强化学习的研究进度，同时让社区更多的参与到这个方向中来，Google AI团队开源了Dopamine，它是一个Tensorflow的框架，旨在更灵活和可重复性的创建实验。

 
![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2018/08/goog.png)
</center >

在[这里](https://github.com/google/dopamine)，你可以找到一个完整的训练数据以及TensorFlow的代码。在受控且灵活的环境下进行简单的实验，它应该是一个完美的选择了。在数据科学家看来，这些听起来就像梦一样。

### 2019强化学习预期的发展趋势

Xander Steenbrugge，作为2018 DataHack大会的演讲者和ArxivInsights频道的创建者，应该说已经是强化学习领域里的专家了。以下是他对强化学习在2019年的预期：

我现在在这信领域能看到三个主要的问题：
>
* 样本复杂：为了学习，代理需要大量的数据经验
* 泛化和迁移学习：在任务A上训练，在相关的任务B上测试
* 分层的强化学习：自动化子目标分解

## AI for Good——通往AI伦理

想像一个由算法控制人类行为的世界吧，这并不仅仅是一个乐观的设想对吧？AI的道德伦理一直是Analytics Vidhya非常热衷讨论问题。在所有的技术讨论中，它会让其它讨论陷入困境。

一小部分公司今年因为身陷Facebook和Google内部充斥着的设计武器的丑闻而颜面扫地。但是这一切促使大公司开始制定规章和指导方针。

关于AI的伦理问题，并不存在一个一劳永逸或者开箱即用的解决方案。它的解决，需要结合细致入微的方案和由领导层给出的结构化的路径共同作用。让我们看一些今年早些时候对这一问题取得突破的举措。

### Google和Microsoft之间的战争

看到大公司把重点放在AI的这个方面是令人振奋的。可以看看这两家公司发布的AI原则：

* [Google的AI原则](https://www.blog.google/technology/ai/ai-principles/)
* [Microsoft的AI原则](https://www.microsoft.com/en-us/ai/our-approach-to-ai)

这些都基本上谈到了AI的公平性以及什么时候在什么地方划清界线。在你开始一个AI工程之前，参考这些原则会是一个好的建议。

### GDPR对局面有什么影响

GDPR法律法规对那些收集用户信息去构建AI应用的公司有很大的影响。GDPR给了用户更多的权利去控制自己的数据。

所以这个政策对AI有什么影响呢？如果没有数据，构建任何模型就都没有了基础。这无疑给社交平台和其它网站提供了工具。GDPR正在进行一个非常引人注目的相关研究，但是现在来看，它限制了AI在很多平台的实用性。

### 2019AI伦理展望

这其实是一个灰色地带。目前没有一个可行的方案去解决它。我们需要一起协作，努力把伦理注入到AI的项目中去。我们该怎么实现这一点呢？就像Analytics Vidhya的CEO Kunal Jain说的那样，我们会制定一个讨论框架，大家可以基于它去讨论这个问题。

我期望看到在组织中加入更多的规则去处理AI伦理的问题。随着AI成为公司的愿景，公司的最佳实践需要重构，组织方式也需要重建。我还希望政府发挥更加积极的作用，制定新的或修改原有的政策。2019将是非常有趣的一年。

## 写在最后

强而有力——这是我对2018年那些令人惊叹的发展的最简洁的表达。今年我是ULMFiT的热心用户，同时我将尽快去探索一下BERT，这将是令人兴奋的时光。

我也非常想听到你的声音，有哪些发展你认为是最重要的？你正在使用文章中提到的工具去工作吗？你对接下来的一年有什么预期？我很期望在留言区看到你的回复。


