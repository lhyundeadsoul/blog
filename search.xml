<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[最佳实践有多重要？]]></title>
    <url>%2F2019%2F04%2F09%2F%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%E6%9C%89%E5%A4%9A%E9%87%8D%E8%A6%81%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[大概率的说，比我们想像的更重要。 一个常见的情况是，很多工具的使用往往提供了一些概念上的扩展点，比如： Tmux提供分屏能力时，给出了session/window/pane等操作实体概念； odps提供计算能力时，给出了project/table/column等实体概念； 这些多层次的实体概念在权限管理、资源分配等管理操作上提供了很多灵活性。但也带来了一个常见的问题：在文档交代不明确的时候，会让使用者在不明确一个概念的系统定位时，出现误用的现象，导致工具本身使用的过程充满了坎坷和限制，达不到最好的使用效果。如： Tmux中，window对应project，pane对应environment，导致session永远没有使用的场景，而大量的window堆积带来了查找上的困难。 ODPS project对应了现实组织中的“部门”，导致业务混杂在一起，依赖关系不明确，统计分析没有可供划分的维度，权限管理基本失效，所有人可以看到所有业务数据。 这时候比较能体现Best Practise的意义： Tmux中，session对应project，window对应environment，pane对应shell，充分利用每一个维度提供的管理能力，管理压力小 odps中，project对应实际中的业务项目，权限和资源在不同的业务特征下，给不同project分配、调整，同时兼顾了灵活、安全。 这一切的前提是要对工具的使用场景和工具里每一个概念的系统定位、背影，以及作者的设计初衷有比较深刻的了解才行。 没有对设计初衷的准确把握，所有feature之和小于工具本身。 反过来说，在设计一个工具时，自动屏蔽掉所有可能出错的路径，让用户没有犯错的机会，是一个工具开发者能力的体现。 P.S.《设计心理学》是唐纳德·诺曼关于设计本质的理论著作，里面对设计本质的概括到今天仍然广泛适用： 示能：告诉你我的feature， e.g. 耳机音量键的设计 约束：根本不给用户犯错的机会，e.g.搜索框的设计 映射：产品设计和日常生活有映射关系，e.g.文件系统里的文件夹 反馈：即刻的有效反馈会粘住用户，e.g.进度条]]></content>
      <tags>
        <tag>最佳实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018 AI&ML（自然语言识别、计算机视觉、强化学习）技术概览及2019技术趋势]]></title>
    <url>%2F2019%2F04%2F02%2F2018-AI-ML%EF%BC%88%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E8%AF%86%E5%88%AB%E3%80%81%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E3%80%81%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%89%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88%E5%8F%8A2019%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF%2F</url>
    <content type="text"><![CDATA[一篇国外AI&amp;ML领域大咖的总结文章，翻译的时候我是奔着“信达雅”去的，结果脸着地还没接住，翻译的水平有限，有兴趣的也可以看原文 前言最近几年，人工智能的热度和机器学习技术的成熟度有了一个梦幻般的增长。这些技术已经从边缘领域发展成为了技术主流，并且已经现如今已经影响了数以百万计的人。各个国家也增加了在AI领域的投入以使自己保持竞争优势。 对于数据科学专家来说情况也是一样的， 在过去几年，即使只懂一点相关工具和技术你就可以高枕无忧了。但是现在已经完全不行了。在这个领域发生了太多事情，且有太多东西需要学习以保持和业界同步，这有时令人难以置信。 这就是我为什么想以一个数据科学从业者的视角，回顾一下在几个关键领域里人工智能领域里都取得了哪些发展？哪些突破？2018发生了些什么？2019又有哪些期待？ 我们将会在文中提到的领域 自然语言处理 计算机视觉 工具和库 强化学习 AI伦理 自然语言处理NLP 让机器理解单词和句子在之前一直是一个梦，即使是人类自己在面对语言巨量的细节时，有时也会显得手足无措。但是2018年绝对是NLP的转折年。 我们已经看到一个接一个的技术突破—— ULMFiT, ELMO, OpenAI的 Transformer 以及 Google的BERT 等等。迁移学习在NLP任务上的成功应用打开了一扇通往无限可能的大门。Sebastian Ruder 的播客让我们相信在他的这个领域里有了多么长足的发展。 现在我们来更细致地看一下这些关键的进展吧。如果你希望在NLP领域里找学习的切入点，或者正在找相关的库，请先确保你已经学习过NLP using Python的课程了。这是一个开始NLP学习的好地方。 ULMFiT由Sebastian Ruder 和 fast.ai的 Jeremy Howard共同设计的ULMFiT是让迁移学习成为热点的首个框架。对于没有多少经验的人来说，它代表了“通用语言模型”，Jeremy和Sebastian在这个框架中真正实现了通用二字的含义，它几乎可以应用于所有NLP任务。 不需要更多的ULMFiT或其它的框架介绍了，因为你根本不需要从头开始训练模型！这些研究人员已经做好了最困难的部分。你只需要在你的项目中，学会并应用他们的研究成果即可。ULMFiT在六个文本分类任务里表现优于其他最先进的方法。 关于如何使用此框架解决文本分类问题，你可以阅读由Prateek写的这个很棒的教程。 ELMoELMo是Embeddings from Language Models的简写，即使不提它奇怪的名字，ELMo在发布后依然能迅速获得机器学习社区的关注。 ELMo在考虑了单词在句子和段落中的上下文之后，使用了各种模型去获知单词的内在含义(embeddings)。语境是一个很重要，同时又大部分人都没有掌握的NLP的组成部分。ELMo使用了双向的LSTMs去理解单词内含(embeddings)。你可以阅读这篇文章去快速了解LSTMs的工作原理。 就像ULMFiT一样，ELMo显著地提高了各种类型NLP任务的计算性能，比如情绪分析和问答分析。可以阅读这篇文章了解更多。 BERT不少专家认为BERT的发布开启了NLP的新纪元。继ULMFiT 和 ELMo之后，BERT在性能表现上碾压了对手。正如原始论文里说的“BERT是概念极简且经验强大的(BERT is conceptually simple and empirically powerful)”。 BERT在11项NLP任务中获得了最优的结果，可以看一下他们在SQuAD基准测试中的表现： SQuAD v1.1 Leaderboard (Oct 8th 2018) Test EM Test F1 1st Place Ensemble – BERT 87.4 93.2 2nd Place Ensemble – nlnet 86.0 91.7 1st Place Single Model – BERT 85.1 91.8 2nd Place Single Model – nlnet 83.5 90.1 你可以在自己的机器上使用PyTorch的实现或者Google的Tensorflow实现去验证这个结果。 我非常肯定你会好奇BERT在这一点上代表了什么。它是翻译机的双向编码表示(Bidirectional Encoder Representations from Transformers)。如果第一次能做对，就会是满分。 Facebook PyTextFacebook怎么会离开赛道呢？他们已经开源了自己的深度学习NLP框架，叫PyText。它在本周初早些时候刚刚发布，所以我还在实验当中，但是从早期的评论来看，是非常有潜力的。根据Facebook发表的研究，PyText使对话模型的准确率提升了10%的同时降低了训练时间。 PyText实际上还是弱于Facebook其它产品的，比如FB Messenger。因此，使用这个框架可以为你的工作(your own portfolio)添加现实世界的价值(除了您将获得的宝贵知识以外)。 你可以在他们的GitHub repo里下载源码。 Google Duplex如果你还没有听说过Google Duplex，那你可能out了。Sundar Pichai 用这个demo震撼了当时在场的观众，并且从那以为它就一直是新闻的头条了。 因为这是一个Google的产品，所以他们很可能会在未来将其开源。这的确是一个非常棒的音频处理应用。当然它也带来了道德和隐私问题，但那是本文后面才要说的了。现在，还是让我们感慨一下这些年我们已经和机器学习走了多远吧。 2019年NLP值得期待的事还有谁比 Sebastian Ruder 他自己更能预测NLP在2019年的发展呢，他的想法如下： 预训练语言模型内含(embeddings)将会变得普遍。不使用此类方法，将很难得到最优的模型。我们将看到预训练的表示( pretrained representations)可以给语言模型内含提供补充的专业信息。我们将可以根据任务的需求组合不同类型的预训练的表示.我们将可以看到会在多语言应用和跨语言模型上会有更多的进展。尤其在跨语言单词内含的基础上，我们将会看到深入的预训练跨语言表示。 计算机视觉 这是现在深度学习领域中最受欢迎的领域了。我认为现在已经渡过了计算机视觉的初期，进入了精炼化的阶段。无论是图像还是视频，我们都已经看到了太多可以轻而易举完成计算机视觉任务的框架。 在 Analytics Vidhya，我们已经用了很多时间去普及这些概念。你可以从这里看到我们关于计算机视觉的文章，主题涵盖了从“在图像和视频中完成物体识别”到“预训练模型列表”，这些资料可以帮助你开始你的深度学习旅程。 以下是我精心挑选的计算机视觉的优秀项目。 如果你对这个领域很好奇（实际上这可能是未来工业界最火的工作之一），那么可以通过学习我们的深度学习和计算机视觉课程。 BigGANsIan Goodfellow在2014年设计了GANs（生成对抗网络）概念，并在随后的时间里这一概念衍生出了很多多样化的应用。每年我们都可以看到这个原始的概念通过调整适应了很多实际的案例。但是有一件事从今年开始发生——机器生成的图像非常好辨认出来。框架里总是会有一些不一致性会导致区别非常明显。 但是最近几个月，这一边界已经开始变得模糊。随着BigGANs的建立，这一边界有可能被彻底消除。看看下面机器生成的图片，你几乎无法看出这些图片有什么问题。无论是忧虑还是兴奋，我们不得不承认GANs正在重塑我们对数字图像（视频）的认知。 对于一些数据科学家来说，这些模型首先在ImageNet上训练，然后是JFT-300M，以展示它们可以很好的从一个数据集迁移到另一个数据集。我同样会引导你到一个可视化理解的GAN的学习页。 Fast.ai可以在18分钟内完成在 ImageNet上的训练这是一个非常大的进展。 我们通常认为要想获得一个合适的深度学习任务，往往需要大量的数据以及繁重的计算任务。这里包括了在ImageNet上从头开始的训练。我可以肯定我们所有人都是这么认为的，而Fast.ai的人找到了这么快的办法证明我们其实想错了。 他们用18分钟训练出的模型可以达到93%的准确率。而他们在blog中提到他们用的硬件，仅是16台包涵了8个 NVIDIA V100 GPU的AWS公开实例。他们是使用Fastai和PyTorch库构建的此算法。 所有这些加在一起的成本仅有40美元！这里有Jeremy关于这项技术更详细的说明。这是所有人的胜利！ NVIDIA的 vid2vid 技术图像处理在最近4、5年有了巨大的飞跃，但是视频呢？事实证明，从单帧到多帧的方法迁移比大多数人想像的还要难一些。你能拿着一个视频的时间序列数据去预测下一帧是什么内容吗？之前有过一些探索，但是最好的结论也都并不明确。 NVIDIA在今年早些时候开源了他们的方案，并获得了广泛的赞誉。他们的vid2vid技术的目标是学习一个从输入视频到输出视频的映射函数，而输出视频可以以令人难以置信的准确度延续了输入视频的内容。 你可以从他们的Github上看到他们的PyTorch的实现。 2019年计算机视觉领域展望正如我之前提到的，我们在2019年应该只会看到一些改进，但不会是大的发明。自动驾驶、人脸识别和虚拟现实貌似都没有什么太多的变化。你可以随便质疑我此处的观点，并加上你的观点，我非常想知道还有什么是我们现在还没看到，但是还值得期待的。 即使有政治因素的干预和政府的许可限制，无人机最终会在美国获得批准（印度还远远不能）。个人角度上说，我希望有更多的研究成果可以在真实场景里实施出来。像CVPR和ICML这些会议已经代表了最新进展，但是他们的成果离现实应用又有多远的距离啊？ 视觉问题解答和视觉对话系统最终可能很快完成他们让人期待以久的首次亮相。这些系统缺少泛化能力，但是值得期待的是，我们将会很快看到一些多模型整合的方案。 有监督学习是今年的主角。我可以打赌在明年它将被用在更多的研究之中。有一个非常棒的学习思路——让我们的输入数据直接决定标签，而不是浪费很多时间手工标注。让我们祈祷吧。 工具和类库本节将会吸引很多数据科学家的注意，因为工具和类库是数据科学家的工作基础。我参与了大量关于哪个工具最好，哪个框架取代了哪个框架，哪个类库是金融计算的代表之类的争论。我相信这些问题有很多也与你的工作相关。 但是有一点我们得承认：我们需要保持对这个领域里最新工具的跟进，否则就会埋下更多的风险。Python极速取代一切并成为行业领导者的故事就是一个充分的例子。虽然很多问题的答案可能是一些主观的选择（比如你们公司用什么工具，你们从现有框架迁移到新框架的可行性决策等），但是如果你现在还没有在考虑最优解决方案，我劝你现在就开始吧。 所以到底明年谁会是头条呢？让我们拭目以待吧。 PyTorch 1.0PyTorch炒作得太厉害了，我在本文已经提到了很多次，我会让我的同事 Faizan Shaikh去介绍这个框架的细节。 这是我非常欣赏的必读文章之一，因为有时候TensorFlow运行会很慢，所以给PyTorch了一个迅速抢占市场的机会，PyTorch流行起来的速度比TensorFlow快了一倍。我看到的大部分开源代码都是对PyTorch概念的实现。这绝非巧合，PyTorch非常灵活，并且它的最新版本已经大规模的增强了Facebook的产品和服务，其中包括每天60亿次的文本翻译工作。 PyTorch的2019年的采用率正在增长，所以对于任何人来说，现在就是上车的好时候。 AutoML自动化机器学习技术在过去几年中取得了很大的进展。一些像RapidMiner, KNIME, DataRobot and H2O.ai这样的公司，凭借着他们出色的产品展示了这项服务巨大的潜力。 你能想像只需要拖拽，而不需要编码就能完成机器学习和深度学习的任务吗？这个场景在未来已经不难实现了。除了这些公司的产品外，机器学习领域还有一个重大的产品发布——Auto Keras！ 它是一个可以执行AutoML任务的开源库，这个项目的初衷是让不懂机器学习的领域专家们也可以使用深度学习技术。你可以在这里看到这个项目，未来几年它将蓄势待发。 TensorFlow.js——浏览器里的深度学习我们已经在IDE和Notebook里设计构建了很多机器学习的模型。为什么不向外走一步，去尝试一些新的技术呢？没错，我们可以在我们的浏览器里的去运行深度学习模型了！ 这要感谢TensorFlow.js项目，它有一些demo，充分展示了这个想法有多酷。以下是TensorFlow.js的三个主要特点： 用JavaScript开发和部署机器学习模型在浏览器里运行已经存在的TensorFlow模型重训练已经存在的TensorFlow模型 2019年AutoML展望我想在本章中只强调AutoML技术。因为我认为这项技术才是未来数据科学领域里的游戏规则改变者。不要只是听我说，让我们来看看H2O.ai的 Marios Michailidis和 Kaggle Grandmaste是怎么看待2019AutoML的： 机器学习在成为未来重要趋势的道路上一路高歌猛进。这一扩展增加了对这一领域熟练应用的需求。鉴于它的成长，自动化是把数据科学资源最优化利用的关键。这一技术的应用范围无限宽广：信用，保险，欺诈，计算机视觉，声学，传感器，推荐器，预测，NLP，你来定义它。在这个领域里工作是一种荣幸。这个重要的趋势可以这么理解： 为辅助描述和理解数据，提供智能化的可视化操作界面 在给定的数据集上寻找、构建、抽象更好的特征 快速建立强大的有预见能力的模型 通过机器学习，给黑盒模型和生产模型提供可解释性 促进这些模型的产生 强化学习 如果让我选一个希望看到更多进展的领域，我想会是强化学习。除了偶尔能看到不定期的头条新闻之外，还没有发现有什么颠覆性的突破。社区里，大家普遍认为它太重数学，没有可以使用的真正可工业化的应用。 虽然这在某种程度上可能是正确的，但是我仍然希望在明年看到更多关于强化学习的使用案例。在我每个月发布的GitHub和Reddit系列里，我倾向于至少保留有一个git仓库或相关讨论。在所有研究方向里，这里可能会诞生下一个重大突破。 OpenAI已经发布了一个非常有用的工具包，可以帮助初学者了解这个领域，你也可以看看这篇对初学者非常友好的文章（对我真的非常有帮助）。 OpenAI在深度强化学习的应用 如果说强化学习的研究进展缓慢，那么相关的教育材料就可以说是非常少了。但是就像OpenAI说的那样，他们已经开源了关于这个主题的一些非常棒的材料。他们管这个项目叫“Spinning Up in Deep RL”，你可以从这里了解到它们。 它是一个非常全面的关于强化学习的资源列表，他们让代码和名词解释保持尽可能简单。它里面包含很多有用的材料，比如强化学习的术语，如何成长为强化学习研究员的建议，一个重要论文的列表，一个拥有非常好文档的代码仓库，甚至还有一些帮助你入门的练习。 不要再拖延，如果你计划入门强化学习，现在就开始吧。 Google开源的Dopamine为了加速强化学习的研究进度，同时让社区更多的参与到这个方向中来，Google AI团队开源了Dopamine，它是一个Tensorflow的框架，旨在更灵活和可重复性的创建实验。 在这里，你可以找到一个完整的训练数据以及TensorFlow的代码。在受控且灵活的环境下进行简单的实验，它应该是一个完美的选择了。在数据科学家看来，这些听起来就像梦一样。 2019强化学习预期的发展趋势Xander Steenbrugge，作为2018 DataHack大会的演讲者和ArxivInsights频道的创建者，应该说已经是强化学习领域里的专家了。以下是他对强化学习在2019年的预期： 我现在在这信领域能看到三个主要的问题： 样本复杂：为了学习，代理需要大量的数据经验 泛化和迁移学习：在任务A上训练，在相关的任务B上测试 分层的强化学习：自动化子目标分解 AI for Good——通往AI伦理想像一个由算法控制人类行为的世界吧，这并不仅仅是一个乐观的设想对吧？AI的道德伦理一直是Analytics Vidhya非常热衷讨论问题。在所有的技术讨论中，它会让其它讨论陷入困境。 一小部分公司今年因为身陷Facebook和Google内部充斥着的设计武器的丑闻而颜面扫地。但是这一切促使大公司开始制定规章和指导方针。 关于AI的伦理问题，并不存在一个一劳永逸或者开箱即用的解决方案。它的解决，需要结合细致入微的方案和由领导层给出的结构化的路径共同作用。让我们看一些今年早些时候对这一问题取得突破的举措。 Google和Microsoft之间的战争看到大公司把重点放在AI的这个方面是令人振奋的。可以看看这两家公司发布的AI原则： Google的AI原则 Microsoft的AI原则 这些都基本上谈到了AI的公平性以及什么时候在什么地方划清界线。在你开始一个AI工程之前，参考这些原则会是一个好的建议。 GDPR对局面有什么影响GDPR法律法规对那些收集用户信息去构建AI应用的公司有很大的影响。GDPR给了用户更多的权利去控制自己的数据。 所以这个政策对AI有什么影响呢？如果没有数据，构建任何模型就都没有了基础。这无疑给社交平台和其它网站提供了工具。GDPR正在进行一个非常引人注目的相关研究，但是现在来看，它限制了AI在很多平台的实用性。 2019AI伦理展望这其实是一个灰色地带。目前没有一个可行的方案去解决它。我们需要一起协作，努力把伦理注入到AI的项目中去。我们该怎么实现这一点呢？就像Analytics Vidhya的CEO Kunal Jain说的那样，我们会制定一个讨论框架，大家可以基于它去讨论这个问题。 我期望看到在组织中加入更多的规则去处理AI伦理的问题。随着AI成为公司的愿景，公司的最佳实践需要重构，组织方式也需要重建。我还希望政府发挥更加积极的作用，制定新的或修改原有的政策。2019将是非常有趣的一年。 写在最后强而有力——这是我对2018年那些令人惊叹的发展的最简洁的表达。今年我是ULMFiT的热心用户，同时我将尽快去探索一下BERT，这将是令人兴奋的时光。 我也非常想听到你的声音，有哪些发展你认为是最重要的？你正在使用文章中提到的工具去工作吗？你对接下来的一年有什么预期？我很期望在留言区看到你的回复。]]></content>
      <categories>
        <category>技术趋势</category>
      </categories>
      <tags>
        <tag>AI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于使用场景谈TestNG+JMockit+AssertJ的最佳实践]]></title>
    <url>%2F2019%2F04%2F02%2F%E5%9F%BA%E4%BA%8E%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E8%B0%88TestNG-JMockit-AssertJ%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[个人对单测的理解 程序的结构只因架构设计变化而变化，方法访问权限在够用的情况下，越小越好，这些不能因为单测的影响而改变。 单测也是代码的一部分，评估需求，排期都要算在内。 交付的标准里应该包括至少90%的单测覆盖率。 单测代码也是要被测试的，所以突变测试(mutation testing)（改程序逻辑，单测应该能用“Fail”检测到这个变更）也要抽样做。 不说Feature，只谈场景分别介绍TestNG/JMockit/AssertJ三个框架feature的文章汗牛充栋，在此不赘述，但是就像《最佳实践有多重要？》这篇文章里提到的，没有最佳实践，很多feature不知道什么情况下适用，慢慢也就忘记还有这样的feature了。 下面列出了一些单测中遇到的比较棘手的场景，和对应的最佳实践，如果有更好的做法，欢迎补充、更新。 场景0，private method，怎么单测？一般有两种处理方式： 反射后，setAccessible(true)，并执行 跟随private的调用方一起单测 个人认为选择的策略是考虑private方法逻辑的独立性，独立性强，入参容易构建，选1，反之，选2。 场景1，void method，且逻辑stateful，怎么单测？Java里的void method往往对应了procedure的概念，而不是function，没有可供assert的输出。如果观察逻辑是有状态的，且被private修饰，可以通过反射+setAccessible(true)的方式拿到对象的状态，再通过assert验证状态的正确性。 场景2，void method，且逻辑stateless，怎么单测？有一种不太常见的情况，逻辑无状态，且method不输出结果，也不输出到对象状态，而是输出到框架和运行环境，几乎没有可以assert的内容。 e.g. ODPS的UDTF 12345public void process(Object[] args) throws UDFException, IOException &#123; for (int i = 0; i &lt;10; i++) &#123; forward(i, "abc");//forward内部实现会因运行环境不同而不同 &#125;&#125; 这种情况可以采用JMockit，将被调用的框架方法“劫持”，把框架方法的实现换成可以产生状态的逻辑，最后输出结果，并assert验证。伪代码如下，注意这里mock的方法并不是public，事实上，即使private也是可以的，这也是JMockit的抓手之一：12345678910List&lt;String&gt; list = Lists.newArrayList(xx,yy,zz);Map&lt;Object, Object&gt; result = Maps.newHashMap();ExpectedTimePositionExplode mock = new MockUp&lt;ExpectedTimePositionExplode&gt;()&#123; @Mock protected void forward(Object... outs) throws UDFException &#123; result.put(outs[0], outs[1]); &#125;&#125;.getMockInstance();mock.process(new Object[]&#123;list&#125;);assertThat(result).hasSize(3).containsValues(0,12,7); 场景3，逻辑里大量和运行环境的交互，构造环境很困难，怎么单测？如果一段逻辑中，大量需要和运行环境交互，这时开发者一般为了避免麻烦，会mock大段逻辑，覆盖率会下降，不推荐。 推荐做法有三种： 基于行为mock： 12345678new Expectations() &#123; &#123; parquetReader.read(); SimpleRecord simpleRecord = new SimpleRecord(); simpleRecord.add("abc", "jared"); result = simpleRecord; &#125;&#125;; 基于对象mock： 1234ExecutionContext mockExecutionContext = new MockUp&lt;ExecutionContext&gt;() &#123; @Mock public void claimAlive() &#123;&#125;&#125;.getMockInstance(); 使用运行环境提供的local-implement，e.g. ODPS SourceInputStream 接口的实现，在运行时有专门的基于网络的实现，且不开源，单测时无法构造，且诸多方法都需要mock，mock时还需要了解每一个API的定义，很麻烦。但是随接口发布的还有一个本地实现 LocalInputStream，单测时可以利用上，个人理解这种本地实现应该就是为了调试方便而设计的。 场景4，逻辑有依赖关系，怎么在单测中体现出来？代码使用了Template模式时，往往父类定义逻辑执行顺序，子类具体实现每一个方法。如下面三个方法执行顺序是setup(初始化) -&gt; extract(正式业务) -&gt; close(关闭资源)12345public abstract class Extractor &#123; public abstract void setup(ExecutionContext ctx, InputStreamSet inputs, DataAttributes attributes); public abstract Record extract() throws IOException; public abstract void close();&#125; 对上面三个方法实现的单测，一般也需要按顺序依次进行，这时可以利用@Test(dependsOnMethods = &quot;setup&quot;)在每一个单测方法上指定依赖的上游，上游完成下游执行；上游报错，下游ignore。 场景5，每次maven构建带单测过程漫长，怎么破？构建时很慢可以采用多线程执行单测，以减少单测时间。 在testng.xml中可以设置thread-count和需要并行执行的单元（方法、类或suite）1&lt;suite name="Concurrency Suite" parallel="methods" thread-count="3" &gt; 同时pom.xml中设置 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;suiteXmlFiles&gt; &lt;suiteXmlFile&gt;src/test/resources/testng.xml&lt;/suiteXmlFile&gt; &lt;/suiteXmlFiles&gt; &lt;/configuration&gt;&lt;/plugin&gt; 值得注意的是，即使在多线程单测环境下，@Test(dependsOnMethods = &quot;method1&quot;)也是得到保证的，依赖关系不会乱，可以放心用。 场景6，验证线程安全性问题，怎么单测？用@Test(threadPoolSize = 3, invocationCount = 6, timeOut = 1000)注解测试方法，可以构造并发执行环境，用于验证线程安全性问题。 e.g.123456789int i = 0;@Test(threadPoolSize = 10, invocationCount = 100, timeOut = 1000)public void method1() &#123; i++;&#125;@Test(dependsOnMethods = "method4")public void method2() &#123; assertThat(i).isEqualTo(100);&#125; 运行method2，结果：123org.junit.ComparisonFailure: Expected :[100]Actual :[97] 场景7，多个边界测试数据测相同逻辑，写多个测试case代码冗长且测试数据不能复用，怎么破？如果你写过这样的单测123456evaluate = distance.evaluate(7);assertThat(evaluate).isGreaterThan(0);evaluate = distanceBucket.evaluate(9);assertThat(evaluate).isGreaterThan(0);evaluate = distanceBucket.evaluate(5);assertThat(evaluate).isGreaterThan(0); 那你可能需要考虑一下@DataProvider注解，帮你分离测试数据和逻辑，逻辑更清晰简洁，还可以实现测试数据的复用。123456789@Test(dataProvider = "ppp")public void testParameters(Integer p) &#123; assertThat(p).isGreaterThan(0);&#125;@DataProvider(name = "ppp")public Object[] paramProvider() &#123; return new Object[] &#123;7, 9, 5&#125;;&#125;]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>UnitTest</tag>
      </tags>
  </entry>
</search>
